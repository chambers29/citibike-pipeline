{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73643b95-f298-4e81-9f14-b46dddcab845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This folder contains all necessary paths for the project.\n",
    "\"\"\"\n",
    "\n",
    "# LOCAL\n",
    "LOCAL_TMP = \"/local_disk0/tmp/citibike\"\n",
    "\n",
    "# ADLS\n",
    "ADLS_DOWNLOADS  = \"abfss://citibike@databricksjm.dfs.core.windows.net/downloads\"\n",
    "ADLS_BRONZE     = \"abfss://citibike@databricksjm.dfs.core.windows.net/bronze\"\n",
    "ADLS_SILVER     = \"abfss://citibike@databricksjm.dfs.core.windows.net/silver\"\n",
    "ADLS_GOLD       = \"abfss://citibike@databricksjm.dfs.core.windows.net/gold\"\n",
    "\n",
    "# S3 BUCKET\n",
    "S3_BUCKET       = \"https://s3.amazonaws.com/tripdata\"\n",
    "\n",
    "import os, re, requests, xml.etree.ElementTree as ET\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "ZIP_RE = re.compile(r\"(\\d{4}(?:\\d{2})?)-citibike-tripdata\\.zip\")\n",
    "\n",
    "def _session() -> requests.Session:\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\"User-Agent\": \"citibike-ingestion/1.0\"})\n",
    "    return s\n",
    "\n",
    "def _download_stream(sess: requests.Session, src_url: str, dest_path: str, chunk=8*1024*1024):\n",
    "    with sess.get(src_url, stream=True, timeout=30) as resp:\n",
    "        resp.raise_for_status()\n",
    "        with open(dest_path, \"wb\") as f:\n",
    "            for part in resp.iter_content(chunk_size=chunk):\n",
    "                if part:\n",
    "                    f.write(part)\n",
    "\n",
    "def download_data(\n",
    "    s3_url: str,\n",
    "    adls_dir_url: str,\n",
    "    dbutils,\n",
    "    local_dir: str,\n",
    "    year_filter: Optional[Tuple[int, int]] = None,\n",
    "    limit: Optional[int] = None\n",
    "):  \n",
    "    # local dir\n",
    "    os.makedirs(local_dir, exist_ok=True)\n",
    "    # cloud dir\n",
    "    dbutils.fs.mkdirs(adls_dir_url)\n",
    "\n",
    "    # existing ADLS filenames\n",
    "    try:\n",
    "        existing = {fi.name.rstrip(\"/\") for fi in dbutils.fs.ls(adls_dir_url)}\n",
    "    except Exception:\n",
    "        dbutils.fs.mkdirs(adls_dir_url)\n",
    "        existing = set()\n",
    "\n",
    "    # list all files in S3 bucket (XML, <Key>)    \n",
    "    list_url = f\"{s3_url.rstrip('/')}/?list-type=2\"\n",
    "    sess = _session()\n",
    "    r = sess.get(list_url, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    keys = [e.text for e in ET.fromstring(r.text).iterfind(\".//{*}Key\")]\n",
    "\n",
    "    # loop through all files and download if not already in ADLS\n",
    "    downloaded = skipped = failed = 0\n",
    "    for i, key in enumerate(keys, start=1):\n",
    "        fname = os.path.basename(key)\n",
    "        if not ZIP_RE.fullmatch(fname):\n",
    "            continue\n",
    "\n",
    "        # filter by year (optional)\n",
    "        if year_filter:\n",
    "            try:\n",
    "                yr = int(fname[:4])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            y1, y2 = year_filter\n",
    "            if not (y1 <= yr <= y2):\n",
    "                continue\n",
    "\n",
    "        # if already exists in ADLS, skip\n",
    "        if fname in existing:\n",
    "            print(f\"[{i}] SKIP (ADLS): {fname}\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        file_url  = f\"{s3_url.rstrip('/')}/{fname}\"\n",
    "        local_path = os.path.join(local_dir, fname)\n",
    "        adls_path  = f\"{adls_dir_url}/{fname}\"\n",
    "\n",
    "        # download single file\n",
    "        print(f\"[{i}] Downloading: {fname}\")\n",
    "        try:\n",
    "            _download_stream(sess, file_url, local_path)\n",
    "            # move to ADLS\n",
    "            dbutils.fs.mv(\"file:\" + local_path, adls_path, True)\n",
    "            print(f\"[{i}] MOVED â†’ ADLS: {fname}\")\n",
    "            existing.add(fname)\n",
    "            downloaded += 1\n",
    "        except Exception as e:\n",
    "            print(f\"[{i}] FAILED {fname}: {e}\")\n",
    "            failed += 1\n",
    "            if os.path.exists(local_path):\n",
    "                try: os.remove(local_path)\n",
    "                except: pass\n",
    "\n",
    "        if limit and downloaded >= limit:\n",
    "            break\n",
    "\n",
    "    return {\"downloaded\": downloaded, \"skipped\": skipped, \"failed\": failed}\n",
    "\n",
    "    \"\"\"\n",
    "Pipeline: Download Citibike ZIP files from S3 and upload them to ADLS (downloads folder).\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.dbutils import DBUtils\n",
    "# from utilities.paths import S3_BUCKET, ADLS_DOWNLOADS, LOCAL_TMP\n",
    "# from utilities.ingestion_utils import download_data\n",
    "\n",
    "\n",
    "def run():\n",
    "    dbu = DBUtils(spark)\n",
    "\n",
    "    stats = download_data(\n",
    "        s3_url=S3_BUCKET,\n",
    "        adls_dir_url=ADLS_DOWNLOADS,\n",
    "        dbutils=dbu,\n",
    "        local_dir=LOCAL_TMP,\n",
    "        year_filter=(2018, 2023),\n",
    "        limit=None               \n",
    "    )\n",
    "\n",
    "    print(\"Ingestion finished.\")\n",
    "    print(f\"Downloaded: {stats['downloaded']} | Skipped: {stats['skipped']} | Failed: {stats['failed']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "815fd49c-871e-46c1-baf1-c44c4928d8d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "```\n",
    "-przechodzi do external data (ADLS) -> folderu downloads\n",
    "-iteruje po plikach (ADLS)\n",
    "  -tworzy folder local_disk0/tmp/citibike \n",
    "  -pobiera do local_disk0/tmp/citibike\n",
    "  -przechodzi do local_disk0/tmp/citibike\n",
    "  -iteruje po plikach (citibike)\n",
    "    -sprawdza czy zip:\n",
    "\n",
    "      TAK: \t-tworzy folder local_disk0/tmp/citibike/extracted\n",
    "            -pobiera cala nazwe archiwum zip\n",
    "            -pobiera 4 pierwsze znaki archiwum zip (rok)\n",
    "            -rozpakowywuje do tmp/extracted\n",
    "            -przechodzi do extracted\n",
    "            -iteruje po kazdym pliku (citibike/extracted)\n",
    "              -sprawdza czy plik jest folderem i nazwa == nazwa archiwum zip:\n",
    "                TAK:  -przechodzi do tego folderu:\n",
    "                      -tworzy folder (nazwa = rok)\n",
    "                      -iteruje po plikach (citibike/extracted/nazwa):\n",
    "                        -sprawdza czy nazwa == (rok):\n",
    "                          TAK:  -continue\n",
    "                          NIE:  -sprawdza czy zip:\n",
    "                                    TAK:  -rozpakowywuje do (rok)\n",
    "                                    NIE:  -sprawdza czy folder:\n",
    "                                            TAK: -zawartosc przenosi do (rok)\n",
    "                                            NIE: -continue\n",
    "                      -przenosi (rok) do ADLS bronze\n",
    "                      -usuwa local_disk0/tmp/citibike\n",
    "\n",
    "                NIE:  -usuwa local_disk0/tmp/citibike\n",
    "                      -break\n",
    "\n",
    "      NIE:  -usuwa local_disk0/tmp/citibike\n",
    "            -break\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "947af58d-2407-416f-b11f-7d29c986cb88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os, zipfile, shutil\n",
    "\n",
    "DOWNLOADS = \"abfss://citibike@databricksjm.dfs.core.windows.net/downloads\"\n",
    "BRONZE = \"abfss://citibike@databricksjm.dfs.core.windows.net/bronze\"\n",
    "LOCAL_TMP = \"/local_disk0/tmp/citibike\"\n",
    "EXTRACTED = f\"{LOCAL_TMP}/extracted\"\n",
    "adls_files = dbutils.fs.ls(DOWNLOADS)\n",
    "\n",
    "# -przechodzi do external data (ADLS) -> folderu downloads\n",
    "# -iteruje po plikach (ADLS)\n",
    "\n",
    "skipped = 0\n",
    "processed = 0\n",
    "\n",
    "for adls_file in adls_files:\n",
    "\n",
    "    # nazwa pliku adls\n",
    "    adls_filename = adls_file.name\n",
    "\n",
    "    # pobranie roku z nazwy pliku\n",
    "    year = adls_filename[:4]\n",
    "    \n",
    "    print(f\"Now processing: {adls_filename}\")\n",
    "\n",
    "    try:\n",
    "        dbutils.fs.ls(f\"{BRONZE}/{year}\")\n",
    "        print(f\"{year} Folder already exists.\\nSkipping...\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "    except:\n",
    "        print(f\"{year} folder doesnt exist.\\nContinuing...\")\n",
    "\n",
    "    # tworzenie folderu lokalnego\n",
    "    os.makedirs(LOCAL_TMP, exist_ok=True)\n",
    "    print(f\"Created local folder: {LOCAL_TMP}\")\n",
    "\n",
    "    # PRZYGOTOWANIE DO KOPII (ADLS -> LOCAL)\n",
    "    # zrodlo\n",
    "    source_path = f\"{DOWNLOADS}/{adls_filename}\"\n",
    "    # cel\n",
    "    destination_path = f\"file:{LOCAL_TMP}/{adls_filename}\"\n",
    "    # przepisanie pliku z ADLS do lokalnego folderu}\"\n",
    "    dbutils.fs.cp(source_path, destination_path)\n",
    "    print(f\"File copied from ADLS to local: {adls_filename}\")\n",
    "\n",
    "    # iteracja po local (citibike)\n",
    "    print(\"Iterating through local...\")\n",
    "    for local_file in os.listdir(LOCAL_TMP):\n",
    "        # sprawdzanie czy zip\n",
    "        if local_file.lower().endswith(\".zip\"):\n",
    "            print(\".zip file found\")\n",
    "            # tworzenie sciezki zipa\n",
    "            zip_path = os.path.join(LOCAL_TMP, local_file)\n",
    "            # tworzenie folderu do wypakowywania\n",
    "            os.makedirs(EXTRACTED, exist_ok=True)\n",
    "            # wypakowanie do extracted\n",
    "            print(f\"Extracting zip file to {EXTRACTED}...\")\n",
    "            with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "                z.extractall(EXTRACTED)\n",
    "            # iteracja po extracted\n",
    "            print(\"Iterating through extracted files...\")\n",
    "            for extracted_file in os.listdir(EXTRACTED):\n",
    "                # sprawdzanie czy to folder o tej samej nazwie jak zip\n",
    "                if extracted_file == adls_filename[:-4]:\n",
    "                    # tworzenie folderu roku\n",
    "                    os.makedirs(f\"{EXTRACTED}/{extracted_file}/{year}\", exist_ok=True)\n",
    "                    # iteracja po plikach w folderze (tym rozpakowanym)\n",
    "                    for file_in_extracted_file in os.listdir(f\"{EXTRACTED}/{extracted_file}\"):\n",
    "                        # sprawdzanie czy to folder typu \"1_\" lub \"12_\" itp.\n",
    "                        if (file_in_extracted_file[1] == '_') or (file_in_extracted_file[2] == '_'):\n",
    "                            print(\"Processing old type\")\n",
    "                            # jesli tak to iteracja po tym folderze\n",
    "                            for file_in_extracted_file_2 in os.listdir(f\"{EXTRACTED}/{extracted_file}/{file_in_extracted_file}\"):\n",
    "                                # przepisanie zawartosci do folderu z rokiem\n",
    "                                # zrodlo\n",
    "                                source_path = f\"{EXTRACTED}/{extracted_file}/{file_in_extracted_file}/{file_in_extracted_file_2}\"\n",
    "                                # cel\n",
    "                                destination_path = f\"{EXTRACTED}/{extracted_file}/{year}\"\n",
    "                                # transfer\n",
    "                                shutil.move(source_path, destination_path)\n",
    "                            # jesli to nie folder typu \"1_\" lub \"12_\" to sprawdzanie czy jest zipem\n",
    "                        elif file_in_extracted_file.endswith(\".zip\"):\n",
    "                            print(\"Processing new type\")\n",
    "                            # jesli zip to wypakowanie do folderu roku\n",
    "                            with zipfile.ZipFile(f\"{EXTRACTED}/{extracted_file}/{file_in_extracted_file}\", \"r\") as z:\n",
    "                                z.extractall(f\"{EXTRACTED}/{extracted_file}/{year}\")\n",
    "                        else: continue\n",
    "                    # przeniesienie do ADLS\n",
    "                    print(f\"Moving extracted files to ADLS: {year}\")\n",
    "                    local = f\"{EXTRACTED}/{extracted_file}/{year}\"\n",
    "                    dbutils.fs.cp(f\"file:{local}\", f\"{BRONZE}/{year}\", recurse=True)\n",
    "                    # usuniecie folderu lokalnego citibike\n",
    "                    shutil.rmtree(LOCAL_TMP)\n",
    "                    print(f\"Removed local folder: {LOCAL_TMP}\")\n",
    "                    print(\"############### DONE ############### \")\n",
    "                    processed += 1\n",
    "            break\n",
    "print(f\"Processed: {processed} | Skipped: {skipped}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73ef9b44-6c17-4485-9fe0-0097ce015d6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.path.exists(LOCAL_TMP)\n",
    "# os.listdir(LOCAL_TMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c77cb78-140d-4b8a-b0f1-eadb9706e8a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "```\n",
    "bronze->silver\n",
    "-wczytanie danych\n",
    "-wybor kolumn\n",
    "-narzucenie typow\n",
    "\n",
    "dodanie kolumn:\n",
    "  -dodanie duration_sec (ended_at - started_at)\n",
    "    -jesli duration_sec > 89970: odrzucic\n",
    "  -rok\n",
    "  -miesiac\n",
    "  -dzien \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38ce73ca-048d-47de-8f3f-5fc4372e3261",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# BRONZE -> SILVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba06ec61-64fe-4ef3-9a84-336ffedebb8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ADLS_BRONZE     = \"abfss://citibike@databricksjm.dfs.core.windows.net/bronze\"\n",
    "ADLS_SILVER     = \"abfss://citibike@databricksjm.dfs.core.windows.net/silver\"\n",
    "\n",
    "\n",
    "df_old = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .load(f\"{ADLS_BRONZE}/2014\")\n",
    ")\n",
    "df_new = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .load(f\"{ADLS_BRONZE}/2020\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26d7482c-5d85-4918-8cb4-23cc78b1fe19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_new.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54005376-cf1c-4c41-ba62-7d2e1e1c1899",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "SILVER_SCHEMA = StructType([\n",
    "    StructField(\"ride_id\",              StringType(),       True),\n",
    "    StructField(\"rideable_type\",        StringType(),       True),\n",
    "    StructField(\"started_at\",           TimestampType(),    True), # starttime\n",
    "    StructField(\"ended_at\",             TimestampType(),    True), # stoptime\n",
    "    StructField(\"start_station_name\",   StringType(),       True), # start station name\n",
    "    StructField(\"start_station_id\",     StringType(),      True), # start station id\n",
    "    StructField(\"end_station_name\",     StringType(),       True), # end station name\n",
    "    StructField(\"end_station_id\",       StringType(),      True), # end station id\n",
    "    StructField(\"start_lat\",            DoubleType(),       True), # start station latitude\n",
    "    StructField(\"start_lng\",            DoubleType(),       True), # start station longitude\n",
    "    StructField(\"end_lat\",              DoubleType(),       True), # end station latitude\n",
    "    StructField(\"end_lng\",              DoubleType(),       True), # end station longitude\n",
    "    StructField(\"member_casual\",        StringType(),       True), # usertype (values: subscriber, customer)\n",
    "    #StructField(\"bikeid\", IntegerType(), True), -bikeid\n",
    "    #StructField(\"birth year\", IntegerType(), True), -birthyear\n",
    "    #StructField(\"gender\", IntegerType(), True) -gender\n",
    "])\n",
    "\n",
    "silver_cols = [f.name for f in SILVER_SCHEMA.fields]\n",
    "silver_types = {f.name: f.dataType for f in SILVER_SCHEMA.fields}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e69a6dc8-c542-43f4-9c69-b6428081c176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ALIASES = {\n",
    "    \"starttime\": \"started_at\",\n",
    "    \"stoptime\": \"ended_at\",\n",
    "    \"start station name\": \"start_station_name\",\n",
    "    \"start station id\": \"start_station_id\",\n",
    "    \"end station name\": \"end_station_name\",\n",
    "    \"end station id\": \"end_station_id\",\n",
    "    \"start station latitude\": \"start_lat\",\n",
    "    \"start station longitude\": \"start_lng\",\n",
    "    \"end station latitude\": \"end_lat\",\n",
    "    \"end station longitude\": \"end_lng\",\n",
    "    \"usertype\": \"member_casual\"\n",
    "}\n",
    "\n",
    "VALUE_MAP = {\n",
    "    \"subscriber\": \"member\",\n",
    "    \"customer\": \"casual\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ead69f5-3193-4bbd-910c-067a6258098d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "```\n",
    "-idzie do bronze\n",
    "-zapisuje nazwy folderow (lata) do listy\n",
    "-robi df wedlug lat z listy\n",
    "-sprawdza format df (stary czy nowy) np if year>2019\n",
    " -jesli nowy to wczytuje df z SILVER_SCHEMA\n",
    " -jesli stary to wczytuje df bez schemy,\n",
    "  -robi mapowania i doprowadza do stanu z SILVER_SCHEMA\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d5c30e1-97e6-44fd-a93e-074d065b0c03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ADLS_BRONZE     = \"abfss://citibike@databricksjm.dfs.core.windows.net/bronze\"\n",
    "\n",
    "years = [year.name for year in dbutils.fs.ls(ADLS_BRONZE)]\n",
    "print(years)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d463c3ff-2009-460d-a3f1-749f27062553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def new_format(df):\n",
    "    return \"member_casual\" in df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a724233d-e9c4-4ee3-b49b-34587fb029c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, lower, lit\n",
    "def normalize_old(df):\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .withColumn(\"ride_id\", lit(None))\n",
    "        .withColumn(\"rideable_type\", lit(None))\n",
    "    )\n",
    "\n",
    "    ALIASES = {\n",
    "        \"starttime\": \"started_at\",\n",
    "        \"stoptime\": \"ended_at\",\n",
    "        \"start station name\": \"start_station_name\",\n",
    "        \"start station id\": \"start_station_id\",\n",
    "        \"end station name\": \"end_station_name\",\n",
    "        \"end station id\": \"end_station_id\",\n",
    "        \"start station latitude\": \"start_lat\",\n",
    "        \"start station longitude\": \"start_lng\",\n",
    "        \"end station latitude\": \"end_lat\",\n",
    "        \"end station longitude\": \"end_lng\",\n",
    "        \"usertype\": \"member_casual\"\n",
    "    }\n",
    "\n",
    "    VALUE_MAP = {\n",
    "        \"subscriber\": \"member\",\n",
    "        \"customer\": \"casual\"\n",
    "    }\n",
    "\n",
    "    # MAPPING COLUMN NAMES\n",
    "    for old_column, new_column in ALIASES.items():\n",
    "        if old_column in df.columns:\n",
    "            df = df.withColumnRenamed(old_column, new_column)\n",
    "        else: print(f\"MAPPING COLUMN NAMES ERROR: Couldn't find column: {old_column}\")\n",
    "    \n",
    "    # MAPPING VALUES MEMBER_CASUAL\n",
    "    if \"member_casual\" in df.columns:\n",
    "        for old_value, new_value in VALUE_MAP.items():\n",
    "            df = df.withColumn(\n",
    "                \"member_casual\",\n",
    "                when(lower(col(\"member_casual\")) == old_value, new_value)\n",
    "                .otherwise(col(\"member_casual\"))\n",
    "            )\n",
    "    else: print(f\"MAPPING VALUES MEMBER_CASUAL ERROR: Couldn't find column: member_casual\")\n",
    "\n",
    "    df = (\n",
    "        df.select(\n",
    "            \"ride_id\",\n",
    "            \"rideable_type\",\n",
    "            \"started_at\",\n",
    "            \"ended_at\",\n",
    "            \"start_station_name\",\n",
    "            \"start_station_id\",\n",
    "            \"end_station_name\",\n",
    "            \"end_station_id\",\n",
    "            \"start_lat\",\n",
    "            \"start_lng\",\n",
    "            \"end_lat\",\n",
    "            \"end_lng\",\n",
    "            \"member_casual\"\n",
    "        )\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea50b950-3098-441a-9ef8-b22e5017ef7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##### CONVERT TO SILVER FORMAT #####\n",
    "def to_silver(df):\n",
    "\n",
    "    SILVER_SCHEMA = StructType([\n",
    "        StructField(\"ride_id\",              StringType(),       True),\n",
    "        StructField(\"rideable_type\",        StringType(),       True),\n",
    "        StructField(\"started_at\",           TimestampType(),    True), # starttime\n",
    "        StructField(\"ended_at\",             TimestampType(),    True), # stoptime\n",
    "        StructField(\"start_station_name\",   StringType(),       True), # start station name\n",
    "        StructField(\"start_station_id\",     StringType(),      True), # start station id\n",
    "        StructField(\"end_station_name\",     StringType(),       True), # end station name\n",
    "        StructField(\"end_station_id\",       StringType(),      True), # end station id\n",
    "        StructField(\"start_lat\",            DoubleType(),       True), # start station latitude\n",
    "        StructField(\"start_lng\",            DoubleType(),       True), # start station longitude\n",
    "        StructField(\"end_lat\",              DoubleType(),       True), # end station latitude\n",
    "        StructField(\"end_lng\",              DoubleType(),       True), # end station longitude\n",
    "        StructField(\"member_casual\",        StringType(),       True), # usertype (values: subscriber, customer)\n",
    "        #StructField(\"bikeid\", IntegerType(), True), -bikeid\n",
    "        #StructField(\"birth year\", IntegerType(), True), -birthyear\n",
    "        #StructField(\"gender\", IntegerType(), True) -gender\n",
    "    ])\n",
    "\n",
    "    silver_cols = [f.name for f in SILVER_SCHEMA.fields]\n",
    "    silver_types = {f.name: f.dataType for f in SILVER_SCHEMA.fields}\n",
    "    return df.select(\n",
    "        [col(c).cast(silver_types[c]) for c in silver_cols]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f53f7b28-9122-49b0-ace5-0e08c3f9ba90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_new1.withColumn(\"duration_sec\", (col(\"ended_at\").cast(\"long\") - col(\"started_at\").cast(\"long\"))).limit(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95a70012-41ca-418e-8c40-70e326cf7156",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_new1 = to_silver(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1525926-d75e-43a7-a5af-00d0f9a90cd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "443709f4-fc51-46f1-84fc-9e794a60dce0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ADLS_SILVER = \"abfss://citibike@databricksjm.dfs.core.windows.net/silver\"\n",
    "df_silver = spark.read.format(\"delta\").load(f\"{ADLS_SILVER}/year=2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39c2e4ac-325f-4987-b91b-108f54b95ae6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "test0",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
